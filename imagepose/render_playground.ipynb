{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render trained appearance networks\n",
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/mnt/qb/work/bethge/ahochlehnert48/code/continual-nerf/inerf/inerf')\n",
    "import typing\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "from nerf_helpers import load_nerf, NeRFAppearance\n",
    "from render_helpers import render, to8b, get_rays\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/mnt/qb/work/bethge/ahochlehnert48/code/continual-nerf/inerf'\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    netdepth=8\n",
    "    netwidth=256\n",
    "    netdepth_fine=8\n",
    "    netwidth_fine=256\n",
    "    chunk=1024*32\n",
    "    netchunk=1024*64\n",
    "\n",
    "    model_name='model_080000'\n",
    "    model_fine_name='model_fine_080000'\n",
    "    # data_dir = './data/nerf_synthetic/'\n",
    "    data_dir = os.path.join(BASE_DIR, 'data/shapenet/chairs_latent/1031fc859dc3177a2f84cb7932f866fd')\n",
    "    ckpt_dir = os.path.join(BASE_DIR, 'nerf/logs/chairs_latent/1031fc859dc3177a2f84cb7932f866fd')\n",
    "    dataset_type='blender'\n",
    "    obs_img_num=1\n",
    "    \n",
    "    use_viewdirs=True\n",
    "    N_importance=64\n",
    "    N_samples=64\n",
    "    white_bkgd=True\n",
    "    \n",
    "    i_embed=0\n",
    "    perturb=0.\n",
    "    raw_noise_std=0.\n",
    "    lindisp=True\n",
    "    multires=10\n",
    "    multires_views=4\n",
    "\n",
    "    # sample_count=10_000\n",
    "    sample_count=250\n",
    "\n",
    "    appearance_dim=3\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load NeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera_angle_x: 0.6911112070083618\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "H, W = 400, 400\n",
    "\n",
    "\n",
    "with open(os.path.join(args.data_dir, 'transforms_test.json'), 'r') as fp:\n",
    "    meta = json.load(fp)\n",
    "frames = meta['frames']\n",
    "\n",
    "# camera_angle_x = 0.691111147403717\n",
    "camera_angle_x = meta['camera_angle_x']\n",
    "print('camera_angle_x:', camera_angle_x)\n",
    "focal = .5 * W / np.tan(.5 * camera_angle_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found keras weights.\n",
      "Reloading from /mnt/qb/work/bethge/ahochlehnert48/code/continual-nerf/inerf/nerf/logs/chairs_latent/1031fc859dc3177a2f84cb7932f866fd/model_080000.npy /mnt/qb/work/bethge/ahochlehnert48/code/continual-nerf/inerf/nerf/logs/chairs_latent/1031fc859dc3177a2f84cb7932f866fd/model_fine_080000.npy\n",
      "Not ndc!\n"
     ]
    }
   ],
   "source": [
    "render_kwargs = load_nerf(args, device, NeRFAppearance)\n",
    "bds_dict = {\n",
    "    'near': 2.,\n",
    "    'far': 9.,\n",
    "}\n",
    "render_kwargs.update(bds_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appearance latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4753,  1.0021,  0.0517],\n",
       "        [-0.0047, -0.0843,  0.6260],\n",
       "        [ 0.8409,  0.4505,  1.1615],\n",
       "        [ 1.0958,  0.9010,  0.5823],\n",
       "        [ 0.0603,  1.2047, -0.0070],\n",
       "        [ 0.8243,  0.8157,  0.8099],\n",
       "        [ 0.2583, -0.2460,  0.4570],\n",
       "        [ 0.3120, -0.4154,  0.2860],\n",
       "        [-0.1711,  0.6088,  0.8479],\n",
       "        [ 1.5499,  0.2115,  0.7491],\n",
       "        [-0.0557,  0.3692,  0.8664],\n",
       "        [ 0.7776,  0.7380,  0.4524],\n",
       "        [ 0.3913,  0.6509,  0.0258],\n",
       "        [ 0.7095,  0.5817,  0.2781],\n",
       "        [ 0.2023,  1.2767,  0.3565],\n",
       "        [-0.0930,  0.6458, -0.1877],\n",
       "        [ 0.1779, -0.1380,  0.5932],\n",
       "        [ 0.4855,  1.1941, -0.2068],\n",
       "        [-0.1362, -0.1328,  0.3789],\n",
       "        [ 0.6889,  0.9539, -0.2104],\n",
       "        [ 0.5552,  0.5888, -0.3360],\n",
       "        [-0.0463,  1.5378,  0.4262],\n",
       "        [-0.0480,  0.3634,  0.9397],\n",
       "        [ 0.4887,  1.0414,  0.2709],\n",
       "        [ 0.7131,  0.5793,  0.1604],\n",
       "        [ 0.6983,  0.5994, -0.0729],\n",
       "        [-0.0564,  0.1222,  0.8267],\n",
       "        [ 0.5403,  0.8629,  0.3155],\n",
       "        [ 1.3958,  0.3544,  0.6843],\n",
       "        [ 0.8418,  0.9717, -0.0267],\n",
       "        [ 0.4125,  0.1822,  0.4528],\n",
       "        [ 0.6177,  0.6212,  0.1582],\n",
       "        [ 0.4060,  0.8924,  0.1117],\n",
       "        [-0.1500,  0.1696,  0.6329],\n",
       "        [-0.1299,  0.1614,  0.5106],\n",
       "        [ 0.9306,  0.4368,  0.9709],\n",
       "        [ 0.9608,  0.8158,  0.9206],\n",
       "        [ 1.0224,  0.6098, -0.0506],\n",
       "        [ 0.5823,  1.0038,  1.0861],\n",
       "        [ 0.7078,  1.0306,  0.5791],\n",
       "        [ 0.8135,  0.9692,  0.5388],\n",
       "        [ 0.2950,  1.3925,  0.3552],\n",
       "        [ 0.3723,  0.2014,  1.1068],\n",
       "        [ 0.2937,  0.7578,  0.3739],\n",
       "        [ 0.5873,  1.0217, -0.2523],\n",
       "        [ 0.3577,  0.6037,  0.3942],\n",
       "        [ 1.0031, -0.2287,  0.4078],\n",
       "        [ 0.6200,  0.2141, -0.1337],\n",
       "        [ 0.8689,  1.0323,  0.7573],\n",
       "        [ 1.0202,  0.4879,  0.6201],\n",
       "        [ 1.2744,  0.2330,  0.6031],\n",
       "        [ 0.2123,  0.4447,  1.1172],\n",
       "        [ 0.0905,  0.2763,  0.7302],\n",
       "        [ 0.1577,  1.2051,  0.3420],\n",
       "        [ 0.0833,  1.1696,  0.2077],\n",
       "        [ 0.3793,  0.7212,  0.3129],\n",
       "        [ 0.0946,  0.1712,  0.7525],\n",
       "        [ 1.2055,  0.4177,  0.9109],\n",
       "        [ 0.7451,  0.4976,  0.4409],\n",
       "        [ 0.0066, -0.1559,  1.0540],\n",
       "        [ 0.5313,  0.5537,  0.1850],\n",
       "        [ 0.4406,  0.8623,  0.4988],\n",
       "        [ 0.5594,  1.0355,  0.2621],\n",
       "        [ 1.2002,  0.6537,  0.6500],\n",
       "        [ 0.0742,  0.1512,  0.7485],\n",
       "        [ 0.3129,  0.2804,  0.3229],\n",
       "        [ 0.9065,  0.8660,  0.7438],\n",
       "        [ 1.0773,  0.7405,  0.8808],\n",
       "        [ 0.1541,  1.2846, -0.0063],\n",
       "        [ 0.4972,  0.9042,  0.3431],\n",
       "        [ 0.4417, -0.2816,  0.7732],\n",
       "        [ 0.5015,  1.2620, -0.0702],\n",
       "        [ 1.0133,  0.2344, -0.1112],\n",
       "        [-0.3052,  0.7686,  0.8008],\n",
       "        [-0.4057,  0.5822,  0.5221],\n",
       "        [ 0.3734,  1.0128,  0.0860],\n",
       "        [ 1.0615,  0.3089,  0.7719],\n",
       "        [ 0.0684, -0.0146,  0.7303],\n",
       "        [ 0.1496,  1.0789,  0.1058],\n",
       "        [ 0.8796,  0.4266,  1.1082],\n",
       "        [ 0.7281,  0.8382, -0.2350],\n",
       "        [-0.0370,  0.0199,  0.6837],\n",
       "        [ 0.6466,  1.3606, -0.0655],\n",
       "        [ 0.6786,  0.7142,  0.4325],\n",
       "        [ 0.8443,  0.4526,  0.1838],\n",
       "        [ 0.5466,  0.2214,  0.3561],\n",
       "        [ 0.5974,  1.3461,  0.8567],\n",
       "        [ 1.1037,  0.7630,  0.6644],\n",
       "        [ 0.8596,  1.1811,  0.9939],\n",
       "        [ 1.4081,  0.0668,  0.6642],\n",
       "        [ 0.5632,  0.5316,  0.2827],\n",
       "        [ 0.1817,  0.3324, -0.2054],\n",
       "        [ 0.4497,  0.2678, -0.0258],\n",
       "        [ 0.1977, -0.0990,  0.6334],\n",
       "        [ 0.0621,  0.1239,  1.1192],\n",
       "        [ 1.0033,  0.9102,  0.6840],\n",
       "        [ 0.2616,  0.8699,  0.1306],\n",
       "        [ 0.7430,  0.6151,  0.2952],\n",
       "        [ 0.9524,  0.7573,  0.6910],\n",
       "        [ 0.5384,  0.6733,  0.5005]], device='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_kwargs['network_fn'].appearance_latents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render appearance latents with fixed pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Render 100 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:57<00:00,  5.79s/it]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "# ani.save('movie.mp4')\n",
    "# plt.show()\n",
    "\n",
    "print(f'Render {len(render_kwargs[\"network_fn\"].appearance_latents)} images')\n",
    "imgs = []\n",
    "frame = frames[10]\n",
    "pose = torch.from_numpy(np.array(frame['transform_matrix'], dtype=np.float32)).cuda()\n",
    "rays_o, rays_d = get_rays(H, W, focal, pose)  # (H, W, 3), (H, W, 3)\n",
    "batch_rays = torch.stack([rays_o, rays_d], 0)\n",
    "for al in tqdm(render_kwargs[\"network_fn\"].appearance_latents[:10]):\n",
    "    render_kwargs['appearance_latent'] = al.cuda()\n",
    "    rgb, disp, acc, extras = render(H, W, focal, chunk=args.chunk, rays=batch_rays,\n",
    "                                    verbose=0 < 10, retraw=True,\n",
    "                                    **render_kwargs)\n",
    "    rgb = rgb.cpu().detach().numpy()\n",
    "    rgb8 = to8b(rgb)\n",
    "    # filename = os.path.join(SAVE_DIR, f'{frame[\"file_path\"]}.png')\n",
    "    # imageio.imwrite(filename, rgb8)\n",
    "    imgs.append(rgb8)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# pls = [plt.imshow(img) for img in imgs]\n",
    "# ani = animation.ArtistAnimation(fig, pls, interval=50, blit=True,\n",
    "#                                 repeat_delay=1000)\n",
    "# plt.show()\n",
    "imageio.mimwrite('APPEARACNCE_video.gif', imgs, fps=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render test poses with foxed appearance latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Render 100 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "print(f'Render {len(render_kwargs[\"network_fn\"].appearance_latents)} images')\n",
    "imgs = []\n",
    "render_kwargs['appearance_latent'] = render_kwargs[\"network_fn\"].appearance_latents[5].cuda()\n",
    "for frame in tqdm(frames):\n",
    "    pose = torch.from_numpy(np.array(frame['transform_matrix'], dtype=np.float32)).cuda()\n",
    "    rays_o, rays_d = get_rays(H, W, focal, pose)  # (H, W, 3), (H, W, 3)\n",
    "    batch_rays = torch.stack([rays_o, rays_d], 0)\n",
    "    rgb, disp, acc, extras = render(H, W, focal, chunk=args.chunk, rays=batch_rays,\n",
    "                                    verbose=0 < 10, retraw=True,\n",
    "                                    **render_kwargs)\n",
    "    rgb = rgb.cpu().detach().numpy()\n",
    "    rgb8 = to8b(rgb)\n",
    "    imgs.append(rgb8)\n",
    "\n",
    "imageio.mimwrite('APPEARACNCE2_video.gif', imgs, fps=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d45ef3ca30c20fe91b40572074cb324cca5edbaf1376c764614da63b2229d598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
